# ğŸ™ï¸ Label Studio Audio Segmentation ML Backend

Backend ML automatique pour Label Studio permettant la segmentation et la classification audio (parole, bruit, silence) avec transcription multilingue via **Whisper**.

## ğŸ“‹ Table des matiÃ¨res
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [DÃ©marrage rapide](#dÃ©marrage-rapide)
- [Architecture](#architecture)
- [Configuration complÃ¨te](#configuration-complÃ¨te)
- [Template Label Studio](#template-label-studio)
- [VÃ©rification et dÃ©bogage](#vÃ©rification-et-dÃ©bogage)
- [Troubleshooting](#troubleshooting)
- [Personnalisation](#personnalisation)

## ğŸš€ FonctionnalitÃ©s

- âœ… **Segmentation automatique** basÃ©e sur la dÃ©tection de silences
- âœ… **Classification** : parole (speech), bruit (noise), silence (silence)
- âœ… **Transcription automatique** des segments de parole avec **Whisper**
- âœ… **DÃ©tection de langue** : franÃ§ais (par dÃ©faut), anglais
- âœ… **ModÃ¨les open-source** prÃ©-entraÃ®nÃ©s (Whisper Tiny)
- âœ… **IntÃ©gration complÃ¨te** avec MinIO + Redis + Label Studio
- âœ… **PrÃ©dictions automatiques** directement dans l'interface

## âš¡ DÃ©marrage rapide

### 1. **Construire et dÃ©marrer les services**

```bash
# Construire et dÃ©marrer tous les services
docker compose up --build -d

# VÃ©rifier l'Ã©tat des services
docker compose ps

# Tous les services doivent Ãªtre "Up" et "healthy"
```

### 2. **AccÃ©der aux interfaces**

| Service | URL | Identifiants | Usage |
|---------|-----|--------------|-------|
| **Label Studio** | http://localhost:8080 | Email: `admin@example.com`<br>Password: `admin123` | Interface d'annotation |
| **MinIO Console** | http://localhost:9001 | User: `minioadmin`<br>Password: `minioadmin123` | Stockage des fichiers audio |
| **ML Backend API** | http://localhost:9090 | - | API des prÃ©dictions |
| **Redis** | localhost:6379 | - | Queue des tÃ¢ches |

### 3. **VÃ©rifier la santÃ© des services**

```bash
# Tester l'API ML Backend
curl http://localhost:9090/health
# Devrait retourner: {"status": "UP"}

# Tester MinIO
curl http://localhost:9000/minio/health/live

# VÃ©rifier Redis
docker-compose exec redis redis-cli ping
# Devrait retourner: PONG
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Label Studio   â”‚
â”‚    :8080        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 1. Demande prÃ©diction
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ML Backend    â”‚â—„â”€â”€â”€â”€â–ºâ”‚    Redis    â”‚
â”‚     :9090       â”‚      â”‚    :6379    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 2. TÃ©lÃ©charge audio
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MinIO       â”‚
â”‚  S3 Storage     â”‚
â”‚     :9000       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Workflow:
1. Utilisateur ouvre une tÃ¢che dans Label Studio
2. Label Studio appelle ML Backend pour les prÃ©dictions
3. ML Backend tÃ©lÃ©charge l'audio depuis MinIO
4. Traitement: Segmentation + Classification + Transcription
5. Retour des rÃ©sultats Ã  Label Studio
6. Affichage des prÃ©-annotations
```

## ğŸ”§ Configuration complÃ¨te

### **Ã‰tape 1 : CrÃ©er un projet dans Label Studio**

1. AccÃ©dez Ã  http://localhost:8080
2. Connectez-vous : `admin@example.com` / `admin123`
3. **Create Project** â†’ Donnez un nom (ex: "Audio Segmentation")
4. Passez Ã  l'Ã©tape suivante

### **Ã‰tape 2 : Configurer le template d'annotation**

Dans **Settings** â†’ **Labeling Interface**, collez ce template :

```xml
<View>
  <Header value="Ã‰couter et valider les segments audio"/>
  
  <!-- Lecteur audio avec contrÃ´les -->
  <Audio name="audio" value="$audio" zoom="true" speed="true" volume="true" hotkey="space"/>
  
  <!-- Labels pour classification -->
  <Labels name="label" toName="audio" choice="single" showInline="true">
    <Label value="speech" background="#4CAF50" hotkey="1"/>
    <Label value="noise" background="#FF9800" hotkey="2"/>
    <Label value="silence" background="#9E9E9E" hotkey="3"/>
  </Labels>
  
  <!-- Zone de transcription -->
  <TextArea 
    name="transcription" 
    toName="audio" 
    editable="true" 
    rows="3"
    maxSubmissions="0"
    showSubmitButton="false"
    placeholder="Transcription automatique (Ã©ditable)"/>
</View>
```

**Cliquez sur "Save"**

### **Ã‰tape 3 : Connecter le ML Backend**

1. Dans votre projet, allez dans **Settings** â†’ **Machine Learning**
2. **Add Model** :
   - **URL** : `http://ml-backend:9090`
   - **Title** : `Audio Segmentation Model`
   - **Description** : `Segmentation et transcription automatique`
3. **Validate and Save**
   - âœ… Devrait afficher "Connected successfully"
   - âŒ Si erreur, consultez [Troubleshooting](#troubleshooting)

4. **Activer les prÃ©dictions automatiques** :
   - â˜‘ï¸ Cochez "Use for interactive preannotations"
   - â˜‘ï¸ Cochez "Retrieve predictions when loading a task"

### **Ã‰tape 4 : Importer des fichiers audio**

**Option A : Via MinIO (recommandÃ© pour gros fichiers)**

```bash
# Copier vos fichiers audio vers MinIO
docker-compose exec minio mc cp /chemin/vers/votre-audio.mp3 myminio/labelstudio/

# Ou via l'interface web MinIO (http://localhost:9001)
# Bucket: labelstudio â†’ Upload
```

Ensuite dans Label Studio :
1. **Settings** â†’ **Cloud Storage** â†’ **Add Source Storage**
2. **Storage Type** : Amazon S3
3. **Configuration** :
   - Storage Title : Un nom arbitraire
   - Bucket Name: `labelstudio`
   - Region Name: Laissez par dÃ©faut
   - S3 Endpoint: http://minio:9000
   - Access Key ID: minioadmin
   - Secret Access Key: minioadmin123
   - **Use pre-signed URLs** : â˜ **DÃ‰COCHER** (important!)
Dans "Import Settings & Preview", faites File Filter Regex: `.*\.(mp3|wav|m4a|ogg|flac)$`
4. **Add Storage** puis **Sync Storage**

**Option B : Upload direct (petit fichiers)**

1. Dans Label Studio, **Import**
2. **Upload Files** â†’ SÃ©lectionner vos fichiers audio
3. **Import**

### **Ã‰tape 5 : Obtenir les prÃ©dictions**

**Les prÃ©dictions se gÃ©nÃ¨rent automatiquement** quand vous :
- Ouvrez une tÃ¢che pour la premiÃ¨re fois
- Cliquez sur le bouton "Get predictions" dans l'interface

Vous devriez voir :
- ğŸŸ¢ Des rÃ©gions colorÃ©es sur la timeline audio
- ğŸ“ Des transcriptions pour les segments de parole
- ğŸ”¢ Un score de confiance pour chaque prÃ©diction

## ğŸ”§ Personnalisation

### **Ajuster les seuils de segmentation**

```python
# Dans audio_segmenter.py, __init__
self.silence_thresh = -50    # Plus sensible (dÃ©tecte plus de parole)
self.min_silence_len = 500   # Silence minimum plus long
```

### **Changer le modÃ¨le Whisper**

```python
# Dans audio_segmenter.py, load_models()
model_id = "openai/whisper-base"   # 74M params, meilleur compromis
# ou
model_id = "openai/whisper-small"  # 244M params, meilleure qualitÃ©
```

### **Ajouter des langues**

```python
# Dans audio_segmenter.py
self.languages = ["fr", "en", "es", "de"]  # Ajouter espagnol, allemand

# Le modÃ¨le dÃ©tecte automatiquement, ou forcez dans _transcribe_segment_whisper
predicted_ids = self.asr_model.generate(
    input_features,
    language=None,  # DÃ©tection automatique
    max_length=225
)
```

### **Modifier les labels**

```python
# Dans model.py
self.labels = ["speech", "noise", "silence", "music", "background"]
```

Et mettez Ã  jour le template XML en consÃ©quence.

## ğŸ“Š Performance

**Temps de traitement typiques** (avec whisper-tiny sur CPU) :
- Audio de 1 minute : ~15-30 secondes
- Audio de 5 minutes : ~60-90 secondes
- Audio de 30 minutes : ~6-8 minutes

**Avec GPU (CUDA)** : environ 5-10x plus rapide

**MÃ©moire requise** :
- whisper-tiny : 2-4 GB RAM
- whisper-small : 4-6 GB RAM
- whisper-medium : 8-10 GB RAM

## ğŸ“ Structure des fichiers

```
project/
â”œâ”€â”€ compose.yml              # Configuration Docker Compose
â”œâ”€â”€ ml-backend/
â”‚   â”œâ”€â”€ Dockerfile          # Image Python avec dÃ©pendances ML
â”‚   â”œâ”€â”€ requirements.txt    # Packages Python
â”‚   â”œâ”€â”€ _wsgi.py           # Point d'entrÃ©e Flask
â”‚   â”œâ”€â”€ model.py           # ModÃ¨le Label Studio ML
â”‚   â”œâ”€â”€ audio_segmenter.py # Logique de segmentation
â”‚   â””â”€â”€ utils.py           # Utilitaires (download, convert)
â””â”€â”€ README.md              # Ce fichier
```

## ğŸ”® Roadmap

- [x] Segmentation basique
- [x] Classification speech/noise/silence
- [x] Transcription avec Whisper
- [x] IntÃ©gration Label Studio + MinIO
- [ ] Support GPU pour accÃ©lÃ©ration
- [ ] Diarization (identification des locuteurs)
- [ ] DÃ©tection d'Ã©motions
- [ ] Support de plus de langues
- [ ] Batch processing asynchrone
- [ ] Interface de monitoring

## ğŸ“„ License

Open-source - Utilisation libre

## â“ Support

**En cas de problÃ¨me** :

1. Consultez les logs : `docker-compose logs -f ml-backend`
2. Lancez le script de vÃ©rification : `./check_setup.sh`
3. VÃ©rifiez cette section de troubleshooting
4. Testez manuellement l'API : `curl http://localhost:9090/predict`

**Les logs du ML Backend sont trÃ¨s verbeux** et vous diront exactement oÃ¹ le problÃ¨me se situe.

---


**Note** : Au premier dÃ©marrage, le ML Backend tÃ©lÃ©charge automatiquement le modÃ¨le Whisper (~150 MB pour whisper-tiny). Cette opÃ©ration prend 2-5 minutes selon votre connexion Internet.


