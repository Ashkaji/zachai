#!/usr/bin/env python3
"""
Script pour pr√©-t√©l√©charger tous les mod√®les n√©cessaires pendant le build Docker.
VERSION ULTRA-ROBUSTE - Ne peut pas √©chouer silencieusement
"""
import os
import sys
import logging
from pathlib import Path

# Configuration du logging AVANT tout
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s | %(message)s',
    stream=sys.stdout  # Forcer stdout pour voir dans les logs Docker
)
logger = logging.getLogger(__name__)

# Forcer les prints √† s'afficher imm√©diatement
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

def print_banner(text):
    """Affiche un banner visible"""
    print("\n" + "=" * 80)
    print(f"  {text}")
    print("=" * 80 + "\n")
    sys.stdout.flush()

def download_whisper_model():
    """T√©l√©charge le mod√®le Whisper - VERSION ULTRA-ROBUSTE"""
    print_banner("üì• D√âBUT DU T√âL√âCHARGEMENT DE WHISPER TINY")
    
    try:
        # Import APR√àS avoir configur√© le logging
        print("‚è≥ Import des librairies transformers...")
        sys.stdout.flush()
        
        from transformers import WhisperProcessor, WhisperForConditionalGeneration
        print("‚úÖ Librairies import√©es avec succ√®s")
        sys.stdout.flush()
        
        model_id = "openai/whisper-tiny"
        model_dir = "/app/models/whisper-tiny"
        
        # Cr√©er le dossier
        print(f"\nüìÅ Cr√©ation du dossier: {model_dir}")
        Path(model_dir).mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Dossier cr√©√©: {model_dir}")
        sys.stdout.flush()
        
        print(f"\nüåê Mod√®le source: {model_id}")
        print(f"üìç Destination: {model_dir}")
        sys.stdout.flush()
        
        # √âTAPE 1: T√©l√©charger le processeur
        print("\n" + "-" * 80)
        print("‚è≥ [1/2] T√âL√âCHARGEMENT DU PROCESSOR")
        print("-" * 80)
        sys.stdout.flush()
        
        processor = WhisperProcessor.from_pretrained(
            model_id,
            cache_dir=None,  # Laisser HF g√©rer le cache
        )
        print("‚úÖ Processor t√©l√©charg√© depuis HuggingFace")
        sys.stdout.flush()
        
        # Sauvegarder explicitement
        print(f"üíæ Sauvegarde dans {model_dir}...")
        sys.stdout.flush()
        
        processor.save_pretrained(model_dir)
        print("‚úÖ Processor sauvegard√© localement")
        sys.stdout.flush()
        
        # √âTAPE 2: T√©l√©charger le mod√®le
        print("\n" + "-" * 80)
        print("‚è≥ [2/2] T√âL√âCHARGEMENT DU MODEL (~150 MB)")
        print("    Ceci peut prendre 1-3 minutes selon votre connexion...")
        print("-" * 80)
        sys.stdout.flush()
        
        model = WhisperForConditionalGeneration.from_pretrained(
            model_id,
            cache_dir=None,
        )
        print("‚úÖ Model t√©l√©charg√© depuis HuggingFace")
        sys.stdout.flush()
        
        # Sauvegarder explicitement
        print(f"üíæ Sauvegarde dans {model_dir}...")
        sys.stdout.flush()
        
        model.save_pretrained(model_dir)
        print("‚úÖ Model sauvegard√© localement")
        sys.stdout.flush()
        
        # V√âRIFICATION D√âTAILL√âE
        print_banner("üîç V√âRIFICATION DES FICHIERS")
        
        if not os.path.exists(model_dir):
            print(f"‚ùå ERREUR CRITIQUE: Le dossier {model_dir} n'existe pas!")
            return False
        
        files = sorted(Path(model_dir).rglob('*'))
        file_list = [f for f in files if f.is_file()]
        
        if not file_list:
            print(f"‚ùå ERREUR CRITIQUE: Aucun fichier dans {model_dir}!")
            return False
        
        total_size = sum(f.stat().st_size for f in file_list)
        total_size_mb = total_size / 1024 / 1024
        
        print(f"üìä Statistiques:")
        print(f"   ‚Ä¢ Nombre de fichiers: {len(file_list)}")
        print(f"   ‚Ä¢ Taille totale: {total_size_mb:.1f} MB")
        print("")
        sys.stdout.flush()
        
        # V√©rifier les fichiers critiques
        print("üìù Fichiers critiques:")
        critical_files = {
            'config.json': False,
            'preprocessor_config.json': False,
            'tokenizer_config.json': False,
            'vocab.json': False,
        }
        
        model_file_found = False
        
        for file_path in file_list:
            filename = file_path.name
            
            # V√©rifier les fichiers critiques
            if filename in critical_files:
                critical_files[filename] = True
                size_kb = file_path.stat().st_size / 1024
                print(f"   ‚úÖ {filename:<35} ({size_kb:>8.1f} KB)")
            
            # V√©rifier le fichier du mod√®le (le plus gros)
            if filename.endswith('.bin') or filename.endswith('.safetensors'):
                model_file_found = True
                size_mb = file_path.stat().st_size / 1024 / 1024
                print(f"   ‚úÖ {filename:<35} ({size_mb:>8.1f} MB) ‚≠ê")
        
        sys.stdout.flush()
        
        # V√©rifier qu'on a tout
        print("")
        missing_files = [name for name, found in critical_files.items() if not found]
        
        if missing_files:
            print(f"‚ùå ERREUR: Fichiers manquants: {', '.join(missing_files)}")
            return False
        
        if not model_file_found:
            print("‚ùå ERREUR: Fichier du mod√®le (.bin ou .safetensors) introuvable!")
            return False
        
        if total_size_mb < 50:
            print(f"‚ùå ERREUR: Taille totale trop petite ({total_size_mb:.1f} MB)")
            print("   Le mod√®le Whisper tiny devrait faire ~150 MB minimum")
            return False
        
        print_banner("‚úÖ ‚úÖ ‚úÖ  SUCC√àS TOTAL  ‚úÖ ‚úÖ ‚úÖ")
        print(f"Le mod√®le Whisper tiny a √©t√© t√©l√©charg√© avec succ√®s!")
        print(f"Emplacement: {model_dir}")
        print(f"Taille: {total_size_mb:.1f} MB")
        print("")
        
        return True
        
    except ImportError as e:
        print_banner("‚ùå ERREUR D'IMPORT")
        print(f"Impossible d'importer transformers: {e}")
        print("")
        print("üí° Solution: V√©rifier que transformers est bien install√©")
        print("   pip install transformers")
        return False
        
    except Exception as e:
        print_banner("‚ùå ERREUR INATTENDUE")
        print(f"Type: {type(e).__name__}")
        print(f"Message: {e}")
        print("")
        
        # Afficher la traceback compl√®te
        import traceback
        print("Traceback complet:")
        traceback.print_exc()
        
        return False

def main():
    """Fonction principale"""
    print("")
    print("=" * 80)
    print("  üöÄ SCRIPT DE T√âL√âCHARGEMENT DES MOD√àLES")
    print("=" * 80)
    print("")
    
    # Afficher la configuration
    print("üìã Configuration:")
    print(f"   ‚Ä¢ Python: {sys.version.split()[0]}")
    print(f"   ‚Ä¢ Working dir: {os.getcwd()}")
    print(f"   ‚Ä¢ TRANSFORMERS_CACHE: {os.environ.get('TRANSFORMERS_CACHE', 'non d√©fini')}")
    print(f"   ‚Ä¢ HF_HOME: {os.environ.get('HF_HOME', 'non d√©fini')}")
    print("")
    sys.stdout.flush()
    
    # T√©l√©charger
    success = download_whisper_model()
    
    print("")
    if success:
        print("=" * 80)
        print("  ‚úÖ ‚úÖ ‚úÖ  T√âL√âCHARGEMENT TERMIN√â AVEC SUCC√àS  ‚úÖ ‚úÖ ‚úÖ")
        print("=" * 80)
        print("")
        sys.exit(0)
    else:
        print("=" * 80)
        print("  ‚ùå ‚ùå ‚ùå  √âCHEC DU T√âL√âCHARGEMENT  ‚ùå ‚ùå ‚ùå")
        print("=" * 80)
        print("")
        print("üîç Debug: Contenu de /app/models/")
        try:
            for item in os.listdir("/app/models"):
                path = os.path.join("/app/models", item)
                if os.path.isdir(path):
                    print(f"   üìÅ {item}/")
                else:
                    size = os.path.getsize(path) / 1024
                    print(f"   üìÑ {item} ({size:.1f} KB)")
        except Exception as e:
            print(f"   Erreur: {e}")
        print("")
        sys.exit(1)

if __name__ == "__main__":
    main()