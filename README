# ğŸ™ï¸ Label Studio Audio Segmentation ML Backend

Backend ML automatique pour Label Studio permettant la segmentation et la classification audio (parole, bruit, silence) avec transcription multilingue via **Whisper**.

## ğŸ“‹ Table des matiÃ¨res
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [DÃ©marrage rapide](#dÃ©marrage-rapide)
- [Architecture](#architecture)
- [Configuration complÃ¨te](#configuration-complÃ¨te)
- [Template Label Studio](#template-label-studio)
- [VÃ©rification et dÃ©bogage](#vÃ©rification-et-dÃ©bogage)
- [Troubleshooting](#troubleshooting)
- [Personnalisation](#personnalisation)

## ğŸš€ FonctionnalitÃ©s

- âœ… **Segmentation automatique** basÃ©e sur la dÃ©tection de silences
- âœ… **Classification** : parole (speech), bruit (noise), silence (silence)
- âœ… **Transcription automatique** des segments de parole avec **Whisper**
- âœ… **DÃ©tection de langue** : franÃ§ais (par dÃ©faut), anglais
- âœ… **ModÃ¨les open-source** prÃ©-entraÃ®nÃ©s (Whisper Tiny)
- âœ… **IntÃ©gration complÃ¨te** avec MinIO + Redis + Label Studio
- âœ… **PrÃ©dictions automatiques** directement dans l'interface

## âš¡ DÃ©marrage rapide

### 1. **Construire et dÃ©marrer les services**

```bash
# Construire et dÃ©marrer tous les services
docker-compose up --build -d

# VÃ©rifier l'Ã©tat des services
docker-compose ps

# Tous les services doivent Ãªtre "Up" et "healthy"
```

### 2. **AccÃ©der aux interfaces**

| Service | URL | Identifiants | Usage |
|---------|-----|--------------|-------|
| **Label Studio** | http://localhost:8080 | Email: `admin@example.com`<br>Password: `admin123` | Interface d'annotation |
| **MinIO Console** | http://localhost:9001 | User: `minioadmin`<br>Password: `minioadmin123` | Stockage des fichiers audio |
| **ML Backend API** | http://localhost:9090 | - | API des prÃ©dictions |
| **Redis** | localhost:6379 | - | Queue des tÃ¢ches |

### 3. **VÃ©rifier la santÃ© des services**

```bash
# Tester l'API ML Backend
curl http://localhost:9090/health
# Devrait retourner: {"status": "UP"}

# Tester MinIO
curl http://localhost:9000/minio/health/live

# VÃ©rifier Redis
docker-compose exec redis redis-cli ping
# Devrait retourner: PONG
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Label Studio   â”‚
â”‚    :8080        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 1. Demande prÃ©diction
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ML Backend    â”‚â—„â”€â”€â”€â”€â–ºâ”‚    Redis    â”‚
â”‚     :9090       â”‚      â”‚    :6379    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 2. TÃ©lÃ©charge audio
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MinIO       â”‚
â”‚  S3 Storage     â”‚
â”‚     :9000       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Workflow:
1. Utilisateur ouvre une tÃ¢che dans Label Studio
2. Label Studio appelle ML Backend pour les prÃ©dictions
3. ML Backend tÃ©lÃ©charge l'audio depuis MinIO
4. Traitement: Segmentation + Classification + Transcription
5. Retour des rÃ©sultats Ã  Label Studio
6. Affichage des prÃ©-annotations
```

## ğŸ”§ Configuration complÃ¨te

### **Ã‰tape 1 : CrÃ©er un projet dans Label Studio**

1. AccÃ©dez Ã  http://localhost:8080
2. Connectez-vous : `admin@example.com` / `admin123`
3. **Create Project** â†’ Donnez un nom (ex: "Audio Segmentation")
4. Passez Ã  l'Ã©tape suivante

### **Ã‰tape 2 : Configurer le template d'annotation**

Dans **Settings** â†’ **Labeling Interface**, collez ce template :

```xml
<View>
  <Header value="Ã‰couter et valider les segments audio"/>
  
  <!-- Lecteur audio avec contrÃ´les -->
  <Audio name="audio" value="$audio" zoom="true" speed="true" volume="true" hotkey="space"/>
  
  <!-- Labels pour classification -->
  <Labels name="label" toName="audio" choice="single" showInline="true">
    <Label value="speech" background="#4CAF50" hotkey="1"/>
    <Label value="noise" background="#FF9800" hotkey="2"/>
    <Label value="silence" background="#9E9E9E" hotkey="3"/>
  </Labels>
  
  <!-- Zone de transcription -->
  <TextArea 
    name="transcription" 
    toName="audio" 
    editable="true" 
    rows="3"
    maxSubmissions="0"
    showSubmitButton="false"
    placeholder="Transcription automatique (Ã©ditable)"/>
</View>
```

**Cliquez sur "Save"**

### **Ã‰tape 3 : Connecter le ML Backend**

1. Dans votre projet, allez dans **Settings** â†’ **Machine Learning**
2. **Add Model** :
   - **URL** : `http://ml-backend:9090`
   - **Title** : `Audio Segmentation Model`
   - **Description** : `Segmentation et transcription automatique`
3. **Validate and Save**
   - âœ… Devrait afficher "Connected successfully"
   - âŒ Si erreur, consultez [Troubleshooting](#troubleshooting)

4. **Activer les prÃ©dictions automatiques** :
   - â˜‘ï¸ Cochez "Use for interactive preannotations"
   - â˜‘ï¸ Cochez "Retrieve predictions when loading a task"

### **Ã‰tape 4 : Importer des fichiers audio**

**Option A : Via MinIO (recommandÃ© pour gros fichiers)**

```bash
# Copier vos fichiers audio vers MinIO
docker-compose exec minio mc cp /chemin/vers/votre-audio.mp3 myminio/labelstudio/

# Ou via l'interface web MinIO (http://localhost:9001)
# Bucket: labelstudio â†’ Upload
```

Ensuite dans Label Studio :
1. **Settings** â†’ **Cloud Storage** â†’ **Add Source Storage**
2. **Storage Type** : Amazon S3
3. **Configuration** :
   - Storage Title : Un nom arbitraire
   - Bucket Name: `labelstudio`
   - Region Name: Laissez par dÃ©faut
   - S3 Endpoint: http://minio:9000
   - Access Key ID: minioadmin
   - Secret Access Key: minioadmin123
   - **Use pre-signed URLs** : â˜ **DÃ‰COCHER** (important!)
Dans "Import Settings & Preview", faites File Filter Regex: `.*\.(mp3|wav|m4a|ogg|flac)$`
4. **Add Storage** puis **Sync Storage**

**Option B : Upload direct (petit fichiers)**

1. Dans Label Studio, **Import**
2. **Upload Files** â†’ SÃ©lectionner vos fichiers audio
3. **Import**

### **Ã‰tape 5 : Obtenir les prÃ©dictions**

**Les prÃ©dictions se gÃ©nÃ¨rent automatiquement** quand vous :
- Ouvrez une tÃ¢che pour la premiÃ¨re fois
- Cliquez sur le bouton "Get predictions" dans l'interface

Vous devriez voir :
- ğŸŸ¢ Des rÃ©gions colorÃ©es sur la timeline audio
- ğŸ“ Des transcriptions pour les segments de parole
- ğŸ”¢ Un score de confiance pour chaque prÃ©diction

## ğŸ“ Template Label Studio

### **Template avancÃ© avec mÃ©tadonnÃ©es**

```xml
<View>
  <Header value="Segmentation et Transcription Audio"/>
  
  <!-- Lecteur audio avec contrÃ´les -->
  <Audio 
    name="audio" 
    value="$audio" 
    speed="true" 
    volume="true" 
    zoom="true"
    hotkey="ctrl+space"/>
  
  <!-- Labels de classification (MULTIPLE car plusieurs segments) -->
  <Header value="Classification des segments"/>
  <Labels name="label" toName="audio">
    <Label value="speech" background="#4CAF50" hotkey="s"/>
    <Label value="noise" background="#FF9800" hotkey="n"/>
    <Label value="silence" background="#9E9E9E" hotkey="i"/>
  </Labels>
  
  <!-- Zone de transcription (liÃ©e aux segments audio) -->
  <Header value="Transcription"/>
  <TextArea 
    name="transcription" 
    toName="audio"
    editable="true"
    perRegion="true"
    rows="3"
    maxSubmissions="0"
    placeholder="Transcription du segment (gÃ©nÃ©rÃ©e automatiquement par Whisper)"/>
</View>
```

## ğŸ” VÃ©rification et dÃ©bogage

### **Script de vÃ©rification automatique**

CrÃ©ez un fichier `check_setup.sh` :

```bash
#!/bin/bash

echo "ğŸ” VÃ©rification de la configuration Label Studio Audio ML"
echo "=========================================================="

# Couleurs
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

check_service() {
    local name=$1
    local url=$2
    local expected=$3
    
    echo -n "Checking $name... "
    response=$(curl -s -o /dev/null -w "%{http_code}" $url)
    
    if [ "$response" -eq "$expected" ]; then
        echo -e "${GREEN}âœ“ OK${NC} (HTTP $response)"
    else
        echo -e "${RED}âœ— FAIL${NC} (HTTP $response, expected $expected)"
    fi
}

echo ""
echo "1ï¸âƒ£  Services HTTP"
echo "-------------------"
check_service "MinIO" "http://localhost:9000/minio/health/live" 200
check_service "ML Backend" "http://localhost:9090/health" 200
check_service "Label Studio" "http://localhost:8080" 200

echo ""
echo "2ï¸âƒ£  Redis"
echo "-------------------"
docker-compose exec -T redis redis-cli ping > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo -e "${GREEN}âœ“ Redis OK${NC}"
else
    echo -e "${RED}âœ— Redis FAIL${NC}"
fi

echo ""
echo "3ï¸âƒ£  MinIO Bucket"
echo "-------------------"
docker-compose exec -T minio mc ls myminio/labelstudio > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo -e "${GREEN}âœ“ Bucket 'labelstudio' exists${NC}"
    file_count=$(docker-compose exec -T minio mc ls myminio/labelstudio | wc -l)
    echo "   Files in bucket: $file_count"
else
    echo -e "${RED}âœ— Bucket 'labelstudio' not found${NC}"
fi

echo ""
echo "4ï¸âƒ£  ML Backend Connection"
echo "-------------------"
# Test depuis le conteneur Label Studio
docker-compose exec -T labelstudio curl -s http://ml-backend:9090/health > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo -e "${GREEN}âœ“ Label Studio can reach ML Backend${NC}"
else
    echo -e "${RED}âœ— Label Studio cannot reach ML Backend${NC}"
fi

echo ""
echo "5ï¸âƒ£  Test de prÃ©diction"
echo "-------------------"
# CrÃ©er un fichier de test
cat > /tmp/test_predict.json << 'EOF'
{
  "tasks": [{
    "id": 999,
    "data": {
      "audio": "http://minio:9000/labelstudio/test.wav"
    }
  }]
}
EOF

response=$(curl -s -X POST http://localhost:9090/predict \
  -H "Content-Type: application/json" \
  -d @/tmp/test_predict.json)

if echo "$response" | grep -q "result"; then
    echo -e "${GREEN}âœ“ ML Backend responds to /predict${NC}"
else
    echo -e "${RED}âœ— ML Backend /predict failed${NC}"
    echo "   Response: $response"
fi

echo ""
echo "=========================================================="
echo "ğŸ VÃ©rification terminÃ©e"
```

Rendez-le exÃ©cutable et lancez-le :

```bash
chmod +x check_setup.sh
./check_setup.sh
```

### **VÃ©rifier les logs en temps rÃ©el**

```bash
# Logs du ML Backend (le plus important)
docker-compose logs -f ml-backend

# Logs de tous les services
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f labelstudio
docker-compose logs -f minio
```

### **Tester manuellement les prÃ©dictions**

```bash
# CrÃ©er un fichier de test
cat > test_predict.json << 'EOF'
{
  "tasks": [{
    "id": 1,
    "data": {
      "audio": "http://minio:9000/labelstudio/votre-fichier.mp3"
    }
  }]
}
EOF

# Appeler l'API
curl -X POST http://localhost:9090/predict \
  -H "Content-Type: application/json" \
  -d @test_predict.json | jq

# La rÃ©ponse devrait contenir des "result" avec les segments
```

### **Inspecter les connexions rÃ©seau**

```bash
# VÃ©rifier que les conteneurs sont sur le mÃªme rÃ©seau
docker network inspect label_studio_network

# Tester la connectivitÃ© inter-conteneurs
docker-compose exec ml-backend ping -c 3 minio
docker-compose exec ml-backend ping -c 3 labelstudio
docker-compose exec labelstudio ping -c 3 ml-backend
```

## ğŸ› Troubleshooting

### **ProblÃ¨me : "Cannot connect to ML Backend"**

**SymptÃ´mes** : Label Studio ne peut pas se connecter au ML Backend

**Solutions** :

```bash
# 1. VÃ©rifier que le ML Backend est en cours d'exÃ©cution
docker-compose ps ml-backend
# Devrait Ãªtre "Up" et "healthy"

# 2. VÃ©rifier les logs
docker-compose logs --tail=50 ml-backend

# 3. Tester depuis Label Studio
docker-compose exec labelstudio curl http://ml-backend:9090/health

# 4. RedÃ©marrer le ML Backend
docker-compose restart ml-backend

# 5. Reconstruire si nÃ©cessaire
docker-compose up -d --build ml-backend
```

**Dans Label Studio**, utilisez bien l'URL : `http://ml-backend:9090` (pas localhost!)

### **ProblÃ¨me : Les prÃ©dictions sont vides**

**SymptÃ´mes** : La connexion fonctionne mais aucun segment n'apparaÃ®t

**Diagnostic** :

```bash
# 1. VÃ©rifier les logs du ML Backend lors d'une prÃ©diction
docker-compose logs -f ml-backend

# Vous devriez voir :
# - "PREDICT called with X tasks"
# - "Downloaded to: /tmp/..."
# - "Converted to WAV: ..."
# - "Generated X segments"

# 2. VÃ©rifier que le fichier audio est accessible
# Essayer de tÃ©lÃ©charger manuellement
docker-compose exec ml-backend curl -I http://minio:9000/labelstudio/votre-fichier.mp3
```

**Solutions** :

1. **Si le tÃ©lÃ©chargement Ã©choue** :
   - VÃ©rifier que le fichier existe dans MinIO
   - VÃ©rifier les permissions du bucket
   - DÃ©sactiver "Use pre-signed URLs" dans la config S3

2. **Si le fichier est tÃ©lÃ©chargÃ© mais vide** :
   - VÃ©rifier le format du fichier audio
   - Essayer de convertir en WAV avant upload

3. **Si le traitement Ã©choue** :
   ```bash
   # Entrer dans le conteneur
   docker-compose exec ml-backend bash
   
   # Installer ffmpeg si manquant
   apt-get update && apt-get install -y ffmpeg
   
   # Tester la conversion
   python -c "from pydub import AudioSegment; AudioSegment.from_file('test.mp3')"
   ```

### **ProblÃ¨me : "Use pre-signed URLs" cause des erreurs**

**SymptÃ´mes** : Erreur 403 ou fichiers inaccessibles

**Solution** : **TOUJOURS dÃ©cocher** cette option dans la configuration S3 de Label Studio

Dans **Settings** â†’ **Cloud Storage** â†’ Votre source S3 :
- â˜ **Use pre-signed URLs** : **DÃ‰COCHER**

Puis **Sync Storage** Ã  nouveau.

### **ProblÃ¨me : Transcriptions vides ou "..."**

**Causes possibles** :
1. Le modÃ¨le Whisper n'est pas chargÃ©
2. Le segment est trop court
3. La qualitÃ© audio est mauvaise
4. La langue dÃ©tectÃ©e est incorrecte

**Solutions** :

```python
# Dans audio_segmenter.py, ligne 35, essayer un modÃ¨le plus gros
model_id = "openai/whisper-small"  # Au lieu de whisper-tiny

# Forcer la langue dans la transcription (ligne 215)
predicted_ids = self.asr_model.generate(
    input_features,
    language="fr",  # Ou "en" selon vos besoins
    max_length=225
)
```

### **ProblÃ¨me : MÃ©moire insuffisante**

**SymptÃ´mes** : Le conteneur ML Backend crash ou devient trÃ¨s lent

**Solutions** :

```yaml
# Dans compose.yml, augmenter les limites
ml-backend:
  mem_limit: 8g        # Au lieu de 6g
  mem_reservation: 6g  # Au lieu de 4g
```

Ou utiliser un modÃ¨le plus lÃ©ger :

```python
# Dans audio_segmenter.py
model_id = "openai/whisper-tiny"  # Le plus lÃ©ger (39M params)
```

### **ProblÃ¨me : URLs localhost au lieu des noms Docker**

**SymptÃ´mes** : Erreur "Connection refused" dans les logs

**Cause** : Les services utilisent `localhost` au lieu des noms de conteneurs

**Solution** : Le code dans `utils.py` convertit automatiquement, mais vÃ©rifiez :

```python
# Dans utils.py, ligne 24-27
url = url.replace('localhost:9000', 'minio:9000')
url = url.replace('localhost:8080', 'labelstudio:8080')
```

### **ProblÃ¨me : Fichiers audio corrompus**

**SymptÃ´mes** : Erreur lors de la conversion WAV

**Diagnostic** :

```bash
# VÃ©rifier le fichier
docker-compose exec ml-backend bash
cd /tmp/label_studio_audio
ls -lh

# Essayer de lire avec ffprobe
ffprobe audio_1.mp3
```

**Solution** :

```bash
# Reconvertir avec ffmpeg
ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav
```

## ğŸ”§ Personnalisation

### **Ajuster les seuils de segmentation**

```python
# Dans audio_segmenter.py, __init__
self.silence_thresh = -50    # Plus sensible (dÃ©tecte plus de parole)
self.min_silence_len = 500   # Silence minimum plus long
```

### **Changer le modÃ¨le Whisper**

```python
# Dans audio_segmenter.py, load_models()
model_id = "openai/whisper-base"   # 74M params, meilleur compromis
# ou
model_id = "openai/whisper-small"  # 244M params, meilleure qualitÃ©
```

### **Ajouter des langues**

```python
# Dans audio_segmenter.py
self.languages = ["fr", "en", "es", "de"]  # Ajouter espagnol, allemand

# Le modÃ¨le dÃ©tecte automatiquement, ou forcez dans _transcribe_segment_whisper
predicted_ids = self.asr_model.generate(
    input_features,
    language=None,  # DÃ©tection automatique
    max_length=225
)
```

### **Modifier les labels**

```python
# Dans model.py
self.labels = ["speech", "noise", "silence", "music", "background"]
```

Et mettez Ã  jour le template XML en consÃ©quence.

## ğŸ“Š Performance

**Temps de traitement typiques** (avec whisper-tiny sur CPU) :
- Audio de 1 minute : ~15-30 secondes
- Audio de 5 minutes : ~60-90 secondes
- Audio de 30 minutes : ~6-8 minutes

**Avec GPU (CUDA)** : environ 5-10x plus rapide

**MÃ©moire requise** :
- whisper-tiny : 2-4 GB RAM
- whisper-small : 4-6 GB RAM
- whisper-medium : 8-10 GB RAM

## ğŸ“ Structure des fichiers

```
project/
â”œâ”€â”€ compose.yml              # Configuration Docker Compose
â”œâ”€â”€ ml-backend/
â”‚   â”œâ”€â”€ Dockerfile          # Image Python avec dÃ©pendances ML
â”‚   â”œâ”€â”€ requirements.txt    # Packages Python
â”‚   â”œâ”€â”€ _wsgi.py           # Point d'entrÃ©e Flask
â”‚   â”œâ”€â”€ model.py           # ModÃ¨le Label Studio ML
â”‚   â”œâ”€â”€ audio_segmenter.py # Logique de segmentation
â”‚   â””â”€â”€ utils.py           # Utilitaires (download, convert)
â””â”€â”€ README.md              # Ce fichier
```

## ğŸ”® Roadmap

- [x] Segmentation basique
- [x] Classification speech/noise/silence
- [x] Transcription avec Whisper
- [x] IntÃ©gration Label Studio + MinIO
- [ ] Support GPU pour accÃ©lÃ©ration
- [ ] Diarization (identification des locuteurs)
- [ ] DÃ©tection d'Ã©motions
- [ ] Support de plus de langues
- [ ] Batch processing asynchrone
- [ ] Interface de monitoring

## ğŸ“„ License

Open-source - Utilisation libre

## â“ Support

**En cas de problÃ¨me** :

1. Consultez les logs : `docker-compose logs -f ml-backend`
2. Lancez le script de vÃ©rification : `./check_setup.sh`
3. VÃ©rifiez cette section de troubleshooting
4. Testez manuellement l'API : `curl http://localhost:9090/predict`

**Les logs du ML Backend sont trÃ¨s verbeux** et vous diront exactement oÃ¹ le problÃ¨me se situe.

---

**Note** : Au premier dÃ©marrage, le ML Backend tÃ©lÃ©charge automatiquement le modÃ¨le Whisper (~150 MB pour whisper-tiny). Cette opÃ©ration prend 2-5 minutes selon votre connexion Internet.